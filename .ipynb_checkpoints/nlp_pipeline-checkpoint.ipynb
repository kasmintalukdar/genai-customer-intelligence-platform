{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c65b3fa6-5b45-4ada-b227-d22110fb65b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n",
      "Loading Sentiment Analysis model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Analysis model loaded.\n",
      "\n",
      "--- Sentiment Analysis Test ---\n",
      "Text: 'The product is amazing, I really love the build quality!'\n",
      "Sentiment: POSITIVE, Score: 0.9999\n",
      "------------------------------\n",
      "\n",
      "Loading Emotion Classification model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion Classification model loaded.\n",
      "\n",
      "--- Emotion Classification Test ---\n",
      "Text: 'I am so frustrated with the customer service, it was a terrible experience.'\n",
      "Emotion: fear, Score: 0.4650\n",
      "------------------------------\n",
      "\n",
      "Loading Summarization model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\genai-customer-intelligence-platform\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\user\\.cache\\huggingface\\hub\\models--facebook--bart-large-cnn. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Device set to use cpu\n",
      "Your max_length is set to 150, but your input_length is only 73. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=36)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarization model loaded.\n",
      "\n",
      "--- Summarization Test ---\n",
      "Original Reviews: ['The battery life is a huge disappointment. It barely lasts a few hours with normal use.', 'I had to charge this device three times yesterday. The battery performance is not as advertised.', \"Connectivity is also a major issue. It keeps disconnecting from my phone's Bluetooth.\", 'While the screen is beautiful, the poor battery makes it almost unusable for me.']\n",
      "\n",
      "Generated Summary:\n",
      "The battery life is a huge disappointment. It barely lasts a few hours with normal use. Connectivity is also a major issue. It keeps disconnecting from my phone's Bluetooth. While the screen is beautiful, the poor battery makes it almost unusable for me.\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Import the pipeline function from the transformers library\n",
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Libraries imported successfully.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. Sentiment Analysis Pipeline\n",
    "# ==============================================================================\n",
    "# Load the pre-trained model for sentiment analysis.\n",
    "# This model classifies text as either 'POSITIVE' or 'NEGATIVE'.\n",
    "print(\"Loading Sentiment Analysis model...\")\n",
    "sentiment_pipeline = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    ")\n",
    "print(\"Sentiment Analysis model loaded.\")\n",
    "\n",
    "def get_sentiment(text):\n",
    "    \"\"\"\n",
    "    Analyzes the sentiment of a given text.\n",
    "    Returns the label ('POSITIVE' or 'NEGATIVE') and the confidence score.\n",
    "    \"\"\"\n",
    "    result = sentiment_pipeline(text)\n",
    "    return result[0]['label'], result[0]['score']\n",
    "\n",
    "# --- Test the sentiment function ---\n",
    "test_text_sentiment = \"The product is amazing, I really love the build quality!\"\n",
    "sentiment_label, sentiment_score = get_sentiment(test_text_sentiment)\n",
    "print(f\"\\n--- Sentiment Analysis Test ---\")\n",
    "print(f\"Text: '{test_text_sentiment}'\")\n",
    "print(f\"Sentiment: {sentiment_label}, Score: {sentiment_score:.4f}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. Emotion Classification Pipeline\n",
    "# ==============================================================================\n",
    "# Load a pre-trained model for classifying emotions.\n",
    "# This model can detect emotions like joy, sadness, anger, etc.\n",
    "print(\"\\nLoading Emotion Classification model...\")\n",
    "emotion_pipeline = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"j-hartmann/emotion-english-distilroberta-base\",\n",
    "    return_all_scores=True\n",
    ")\n",
    "print(\"Emotion Classification model loaded.\")\n",
    "\n",
    "def get_emotion(text):\n",
    "    \"\"\"\n",
    "    Analyzes the primary emotion of a given text.\n",
    "    Returns the emotion with the highest score.\n",
    "    \"\"\"\n",
    "    # The pipeline returns a list of dictionaries for each emotion.\n",
    "    # We find the one with the highest score.\n",
    "    scores = emotion_pipeline(text)[0]\n",
    "    primary_emotion = max(scores, key=lambda x: x['score'])\n",
    "    return primary_emotion['label'], primary_emotion['score']\n",
    "\n",
    "# --- Test the emotion function ---\n",
    "test_text_emotion = \"I am so frustrated with the customer service, it was a terrible experience.\"\n",
    "emotion_label, emotion_score = get_emotion(test_text_emotion)\n",
    "print(f\"\\n--- Emotion Classification Test ---\")\n",
    "print(f\"Text: '{test_text_emotion}'\")\n",
    "print(f\"Emotion: {emotion_label}, Score: {emotion_score:.4f}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. Abstractive Summarization Pipeline\n",
    "# ==============================================================================\n",
    "# Load a pre-trained model for summarization.\n",
    "# This model generates a new summary (abstractive) rather than just extracting sentences.\n",
    "print(\"\\nLoading Summarization model...\")\n",
    "summarizer_pipeline = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "print(\"Summarization model loaded.\")\n",
    "\n",
    "def get_summary(list_of_texts):\n",
    "    \"\"\"\n",
    "    Generates a summary from a list of text strings.\n",
    "    Joins the texts together before summarizing.\n",
    "    \"\"\"\n",
    "    # Join all reviews into a single block of text\n",
    "    full_text = \" \".join(list_of_texts)\n",
    "    \n",
    "    # Generate summary. We set a min and max length for the output.\n",
    "    # Note: BART has a max input length of 1024 tokens. We'll truncate for this example.\n",
    "    summary = summarizer_pipeline(\n",
    "        full_text[:1024],\n",
    "        max_length=150,\n",
    "        min_length=40,\n",
    "        do_sample=False\n",
    "    )\n",
    "    return summary[0]['summary_text']\n",
    "\n",
    "# --- Test the summarization function ---\n",
    "test_reviews_for_summary = [\n",
    "    \"The battery life is a huge disappointment. It barely lasts a few hours with normal use.\",\n",
    "    \"I had to charge this device three times yesterday. The battery performance is not as advertised.\",\n",
    "    \"Connectivity is also a major issue. It keeps disconnecting from my phone's Bluetooth.\",\n",
    "    \"While the screen is beautiful, the poor battery makes it almost unusable for me.\"\n",
    "]\n",
    "generated_summary = get_summary(test_reviews_for_summary)\n",
    "print(f\"\\n--- Summarization Test ---\")\n",
    "print(f\"Original Reviews: {test_reviews_for_summary}\")\n",
    "print(f\"\\nGenerated Summary:\\n{generated_summary}\")\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b694bba-ab2d-44b5-b6c0-5d6ce8fe9402",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
